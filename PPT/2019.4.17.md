# Today's goal write the resnet!

Pre-trained models present in Keras

- 保存模型：保存是为了可以方便的迁移学习，把网络结构和权重分开保存，当然也可以直接一起保存，需要的导入： from keras.models import model_from_yaml, load_model 

深度学习工程师50%的时间在调参数，49%的时间在对抗过/欠拟合，剩下1%时间在修改网上down下来的程序





train_generator = train_datagen.flow_from_directory(
        '/.../train', 
        target_size=(150, 150),  # all images will be resized to 150x150
        batch_size=32,
        class_mode='categorical')                       # matt，多分类

validation_generator = test_datagen.flow_from_directory(
        '/.../validation',
        target_size=(150, 150),
        batch_size=32,
        class_mode='categorical')                      # matt，多分类 
        class_mode='binary



DM train : val : test= 33983  5664 11328

DR train : val : test=





要回答这个问题，首先需要简单谈一下keras的历史。keras是François Chollet于2014-2015年开始编写的开源高层深度学习API。所谓“高层”，是相对于“底层”运算而言（例如add，matmul，transpose，conv2d）。keras把这些底层运算封装成一些常用的神经网络模块类型（例如Dense, Conv2D, LSTM等），再加上像Model、Optimizer等的一些的抽象，来增强API的易用性和代码的可读性，提高深度学习开发者编写模型的效率。keras本身并不具备底层运算的能力，所以它需要和一个具备这种底层运算能力的backend（后端）协同工作。keras的特性之一就是**可以互换的后端**，你在所有后端上写的keras代码都是一样的。从一个后端训练并存储的模型，可以用别的后端加载并运行。

keras最初发行的时候，tensorflow还没有开源（fchollet开始写keras的时候还未加入Google）。那时的keras主要使用的是Theano后端。2015年底TensorFlow开源后，keras才开始搭建TensorFlow后端。今天TensorFlow是keras最常用的后端。

2016－2017年间，Google Brain组根据开源用户对TensorFlow易用性的反馈，决定采纳keras为首推、并内置支持的高层API。当时TensorFlow已经有tf.estimator、slim、sonnet、TensorLayers等诸多高层次API，选择keras主要是考虑它的优秀性以及在用户群中的受欢迎程度，不过那个是另一个故事线就不展开说了。

所以，keras的代码被逐渐吸收进入tensorflow的代码库，那时fchollet也加入了Google Brain组。所以就产生了**tf.keras：一个不强调后端可互换性、和tensorflow更紧密整合、得到tensorflow其他组建更好支持、且符合keras标准的高层次API**。



## **Epoch、Batch Size、和迭代**

2274/2274 [==============================] - 857s 377ms/step - loss: 0.3735 - acc: 0.8239 

- val_loss: 0.3766 - val_acc: 0.8063
Epoch 38/500
2274/2274 [==============================] - 862s 379ms/step - loss: 0.3712 - acc: 0.8244 - val_loss: 0.3770 - val_acc: 0.8000
Epoch 39/500
2274/2274 [==============================] - 863s 380ms/step - loss: 0.3712 - acc: 0.8252 - val_loss: 0.3760 - val_acc: 0.8094
Epoch 40/500
2274/2274 [==============================] - 864s 380ms/step - loss: 0.3682 - acc: 0.8265 - val_loss: 0.3758 - val_acc: 0.8031
Epoch 41/500
2274/2274 [==============================] - 868s 382ms/step - loss: 0.3657 - acc: 0.8284 - val_loss: 0.3741 - val_acc: 0.8000
Epoch 42/500
2274/2274 [==============================] - 876s 385ms/step - loss: 0.3665 - acc: 0.8270 - val_loss: 0.3789 - val_acc: 0.7875
Epoch 43/500
2274/2274 [==============================] - 885s 389ms/step - loss: 0.3670 - acc: 0.8294 - val_loss: 0.3729 - val_acc: 0.8031
Epoch 44/500
2274/2274 [==============================] - 869s 382ms/step - loss: 0.3665 - acc: 0.8286 - val_loss: 0.3800 - val_acc: 0.7969

```
    """
    Implementation of the identity block as defined in Figure 3
    
    Arguments:
    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)
    f -- integer, specifying the shape of the middle CONV's window for the main path
    filters -- python list of integers, defining the number of filters in the CONV layers of the main path
    stage -- integer, used to name the layers, depending on their position in the network
    block -- string/character, used to name the layers, depending on their position in the network
    
    Returns:
    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)
    """
```



Epoch 45/500
2274/2274 [==============================] - 882s 388ms/step - loss: 0.3657 - acc: 0.8298 - val_loss: 0.3782 - val_acc: 0.7906
Epoch 46/500
2274/2274 [==============================] - 867s 381ms/step - loss: 0.3646 - acc: 0.8288 - val_loss: 0.3756 - val_acc: 0.7969

('loss', 0.37698638439178467)
('acc', 0.84375)









Epoch 1/100
1137/1137 [==============================] - 26139s 23s/step - loss: 0.6811 - acc: 0.5916 - val_loss: 0.5974 - val_acc: 0.6594
Epoch 2/100
1137/1137 [==============================] - 26013s 23s/step - loss: 0.5763 - acc: 0.6860 - val_loss: 0.5436 - val_acc: 0.7000
Epoch 3/100
1137/1137 [==============================] - 26035s 23s/step - loss: 0.5367 - acc: 0.7146 - val_loss: 0.5173 - val_acc: 0.7063
Epoch 4/100
1137/1137 [==============================] - 25990s 23s/step - loss: 0.5175 - acc: 0.7275 - val_loss: 0.4960 - val_acc: 0.7156
Epoch 5/100
1137/1137 [==============================] - 25977s 23s/step - loss: 0.5019 - acc: 0.7370 - val_loss: 0.4889 - val_acc: 0.7406
Epoch 6/100

select count(*) as cmt from people where (died is null or died >2012) and (gender ="M" and first_name="Alex")



select year_released, max(cnt)as cnt from(select year_released,count(*) as cnt from movies where (year_released >=2000 and year_released <=2015 and country =="us")  group by year_released)



```sqlite
select count(*) as cmt from people where (died is null or died >2012) and (gender ="M" and first_name="Alex");

select year_released, max(cnt)as cnt from(select year_released,count(*) as cnt from movies where (year_released >=2000 and year_released <=2015 and country =="us")  group by year_released);


select year_released,count(*) as cnt from movies where (year_released >=2000 and year_released <=2015 and country =="us")  group by year_released having cnt=(select max(cnn)as cnm from(select year_released,count(*) as cnn from movies where (year_released >=2000 and year_released <=2015 and country =="us")  group by year_released));



--select first_name,count(*) as cnt from people where gender="F" and born=1989  group by first_name having  count(*)=(
--select max(cnn) from(select first_name, count(*) as cnn from people where gender="F" and born=1989 group by first_name));

--select first_name,c from(select first_name,count(*)as c from
  --   (select * from people where gender="F" and born=1989) group by first_name);

select count(*) as cnt from people where gender="F" and peopleid in
             (select credits.peopleid from credits where movieid in (select movieid from movies where title like "%Avengers%"));


select first_name,surname from people where gender="F" and peopleid in
(select peopleid from (select credits.peopleid,count(*) as cnn from credits where movieid in (select movieid from movies where year_released >2000) group by peopleid) where cnn>20);

select country_code,count(*) from countries where country_code not in (select country from movies) group by continent;


select first_name,surname,peopleid from people where peopleid in (select peopleid from(select peopleid,count(*)as cnt from credits where peopleid in
(select people.peopleid from people where born>=1910 and born<=1932) group by peopleid having cnt =
(select max(cn) from(select count(*)as cn from credits where peopleid in
(select people.peopleid from people where born>=1910 and born<=1932) group by peopleid))));

select first_name,surname from people where peopleid in (select peopleid from(select peopleid,count(*)as cnt from credits where peopleid in
(select people.peopleid from people where born>=1910 and born<=1932) group by peopleid having cnt =;



--select max(cn) from(

select first_name,surname,peopleid,born from people where(first_name="Robert");

  select movieid,peopleid,count(*)as cn from credits where peopleid in
(select people.peopleid from people where (born>=1910 and born<=1932)) group by peopleid
order by cn desc;

select peopleid, born from people where first_name ="Trevor" and surname="Howard";
```

